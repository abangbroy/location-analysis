{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8363c45c-3418-4051-a59a-bd4961cf02dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files loaded successfully!\n",
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "Could not create share link. Please check your internet connection or our status page: https://status.gradio.app.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date           Reference_Id geohash5 geohash6  hour       agegender  \\\n",
      "0 2025-06-01  JPN-JEK-D-00000-00029    xn777   xn777c     5    female_10_19   \n",
      "1 2025-06-01  JPN-JEK-D-00000-00029    xn777   xn777c     5    female_20_29   \n",
      "2 2025-06-01  JPN-JEK-D-00000-00029    xn777   xn777c     5    female_30_39   \n",
      "3 2025-06-01  JPN-JEK-D-00000-00029    xn777   xn777c     5    female_40_49   \n",
      "4 2025-06-01  JPN-JEK-D-00000-00029    xn777   xn777c     5    female_50_59   \n",
      "5 2025-06-01  JPN-JEK-D-00000-00029    xn777   xn777c     5  female_60_plus   \n",
      "6 2025-06-01  JPN-JEK-D-00000-00029    xn777   xn777c     5      male_10_19   \n",
      "7 2025-06-01  JPN-JEK-D-00000-00029    xn777   xn777c     5      male_20_29   \n",
      "8 2025-06-01  JPN-JEK-D-00000-00029    xn777   xn777c     5      male_30_39   \n",
      "9 2025-06-01  JPN-JEK-D-00000-00029    xn777   xn777c     5      male_40_49   \n",
      "\n",
      "  weather  spotsPerHour  spotDuration  dwellTime  loopLength  \\\n",
      "0    rain            10            15         10         360   \n",
      "1    rain            10            15         10         360   \n",
      "2    rain            10            15         10         360   \n",
      "3    rain            10            15         10         360   \n",
      "4    rain            10            15         10         360   \n",
      "5    rain            10            15         10         360   \n",
      "6    rain            10            15         10         360   \n",
      "7    rain            10            15         10         360   \n",
      "8    rain            10            15         10         360   \n",
      "9    rain            10            15         10         360   \n",
      "\n",
      "                 Day_Type day_of_week  \n",
      "0  Public_Holiday/Weekend      Sunday  \n",
      "1  Public_Holiday/Weekend      Sunday  \n",
      "2  Public_Holiday/Weekend      Sunday  \n",
      "3  Public_Holiday/Weekend      Sunday  \n",
      "4  Public_Holiday/Weekend      Sunday  \n",
      "5  Public_Holiday/Weekend      Sunday  \n",
      "6  Public_Holiday/Weekend      Sunday  \n",
      "7  Public_Holiday/Weekend      Sunday  \n",
      "8  Public_Holiday/Weekend      Sunday  \n",
      "9  Public_Holiday/Weekend      Sunday  \n",
      "CSV generated: C:\\Users\\User\\AppData\\Local\\Temp\\tmp173ttd2i.csv\n",
      "Error generating Excel report: At least one sheet must be visible\n",
      "Error generating Excel report: At least one sheet must be visible\n",
      "        date           Reference_Id geohash5 geohash6  hour       agegender  \\\n",
      "0 2025-05-01  JPN-JEK-D-00000-00049    xn775   xn775j     5    female_10_19   \n",
      "1 2025-05-01  JPN-JEK-D-00000-00049    xn775   xn775j     5    female_20_29   \n",
      "2 2025-05-01  JPN-JEK-D-00000-00049    xn775   xn775j     5    female_30_39   \n",
      "3 2025-05-01  JPN-JEK-D-00000-00049    xn775   xn775j     5    female_40_49   \n",
      "4 2025-05-01  JPN-JEK-D-00000-00049    xn775   xn775j     5    female_50_59   \n",
      "5 2025-05-01  JPN-JEK-D-00000-00049    xn775   xn775j     5  female_60_plus   \n",
      "6 2025-05-01  JPN-JEK-D-00000-00049    xn775   xn775j     5      male_10_19   \n",
      "7 2025-05-01  JPN-JEK-D-00000-00049    xn775   xn775j     5      male_20_29   \n",
      "8 2025-05-01  JPN-JEK-D-00000-00049    xn775   xn775j     5      male_30_39   \n",
      "9 2025-05-01  JPN-JEK-D-00000-00049    xn775   xn775j     5      male_40_49   \n",
      "\n",
      "  weather  spotsPerHour  spotDuration  dwellTime  loopLength Day_Type  \\\n",
      "0   sunny            10            15         10         360  Weekday   \n",
      "1   sunny            10            15         10         360  Weekday   \n",
      "2   sunny            10            15         10         360  Weekday   \n",
      "3   sunny            10            15         10         360  Weekday   \n",
      "4   sunny            10            15         10         360  Weekday   \n",
      "5   sunny            10            15         10         360  Weekday   \n",
      "6   sunny            10            15         10         360  Weekday   \n",
      "7   sunny            10            15         10         360  Weekday   \n",
      "8   sunny            10            15         10         360  Weekday   \n",
      "9   sunny            10            15         10         360  Weekday   \n",
      "\n",
      "  day_of_week  \n",
      "0    Thursday  \n",
      "1    Thursday  \n",
      "2    Thursday  \n",
      "3    Thursday  \n",
      "4    Thursday  \n",
      "5    Thursday  \n",
      "6    Thursday  \n",
      "7    Thursday  \n",
      "8    Thursday  \n",
      "9    Thursday  \n",
      "        date           Reference_Id geohash5 geohash6  hour       agegender  \\\n",
      "0 2025-05-01  JPN-JEK-D-00000-00049    xn775   xn775j     5    female_10_19   \n",
      "1 2025-05-01  JPN-JEK-D-00000-00049    xn775   xn775j     5    female_20_29   \n",
      "2 2025-05-01  JPN-JEK-D-00000-00049    xn775   xn775j     5    female_30_39   \n",
      "3 2025-05-01  JPN-JEK-D-00000-00049    xn775   xn775j     5    female_40_49   \n",
      "4 2025-05-01  JPN-JEK-D-00000-00049    xn775   xn775j     5    female_50_59   \n",
      "5 2025-05-01  JPN-JEK-D-00000-00049    xn775   xn775j     5  female_60_plus   \n",
      "6 2025-05-01  JPN-JEK-D-00000-00049    xn775   xn775j     5      male_10_19   \n",
      "7 2025-05-01  JPN-JEK-D-00000-00049    xn775   xn775j     5      male_20_29   \n",
      "8 2025-05-01  JPN-JEK-D-00000-00049    xn775   xn775j     5      male_30_39   \n",
      "9 2025-05-01  JPN-JEK-D-00000-00049    xn775   xn775j     5      male_40_49   \n",
      "\n",
      "  weather  spotsPerHour  spotDuration  dwellTime  loopLength Day_Type  \\\n",
      "0   sunny            10            15         10         360  Weekday   \n",
      "1   sunny            10            15         10         360  Weekday   \n",
      "2   sunny            10            15         10         360  Weekday   \n",
      "3   sunny            10            15         10         360  Weekday   \n",
      "4   sunny            10            15         10         360  Weekday   \n",
      "5   sunny            10            15         10         360  Weekday   \n",
      "6   sunny            10            15         10         360  Weekday   \n",
      "7   sunny            10            15         10         360  Weekday   \n",
      "8   sunny            10            15         10         360  Weekday   \n",
      "9   sunny            10            15         10         360  Weekday   \n",
      "\n",
      "  day_of_week  \n",
      "0    Thursday  \n",
      "1    Thursday  \n",
      "2    Thursday  \n",
      "3    Thursday  \n",
      "4    Thursday  \n",
      "5    Thursday  \n",
      "6    Thursday  \n",
      "7    Thursday  \n",
      "8    Thursday  \n",
      "9    Thursday  \n",
      "CSV generated: C:\\Users\\User\\AppData\\Local\\Temp\\tmp6rmolxlo.csv\n",
      "        date           Reference_Id geohash5 geohash6  hour       agegender  \\\n",
      "0 2025-05-01  JPN-JEK-D-00000-00029    xn777   xn777c     5    female_10_19   \n",
      "1 2025-05-01  JPN-JEK-D-00000-00029    xn777   xn777c     5    female_20_29   \n",
      "2 2025-05-01  JPN-JEK-D-00000-00029    xn777   xn777c     5    female_30_39   \n",
      "3 2025-05-01  JPN-JEK-D-00000-00029    xn777   xn777c     5    female_40_49   \n",
      "4 2025-05-01  JPN-JEK-D-00000-00029    xn777   xn777c     5    female_50_59   \n",
      "5 2025-05-01  JPN-JEK-D-00000-00029    xn777   xn777c     5  female_60_plus   \n",
      "6 2025-05-01  JPN-JEK-D-00000-00029    xn777   xn777c     5      male_10_19   \n",
      "7 2025-05-01  JPN-JEK-D-00000-00029    xn777   xn777c     5      male_20_29   \n",
      "8 2025-05-01  JPN-JEK-D-00000-00029    xn777   xn777c     5      male_30_39   \n",
      "9 2025-05-01  JPN-JEK-D-00000-00029    xn777   xn777c     5      male_40_49   \n",
      "\n",
      "  weather  spotsPerHour  spotDuration  dwellTime  loopLength Day_Type  \\\n",
      "0   sunny            10            15         10         360  Weekday   \n",
      "1   sunny            10            15         10         360  Weekday   \n",
      "2   sunny            10            15         10         360  Weekday   \n",
      "3   sunny            10            15         10         360  Weekday   \n",
      "4   sunny            10            15         10         360  Weekday   \n",
      "5   sunny            10            15         10         360  Weekday   \n",
      "6   sunny            10            15         10         360  Weekday   \n",
      "7   sunny            10            15         10         360  Weekday   \n",
      "8   sunny            10            15         10         360  Weekday   \n",
      "9   sunny            10            15         10         360  Weekday   \n",
      "\n",
      "  day_of_week  \n",
      "0    Thursday  \n",
      "1    Thursday  \n",
      "2    Thursday  \n",
      "3    Thursday  \n",
      "4    Thursday  \n",
      "5    Thursday  \n",
      "6    Thursday  \n",
      "7    Thursday  \n",
      "8    Thursday  \n",
      "9    Thursday  \n",
      "CSV generated: C:\\Users\\User\\AppData\\Local\\Temp\\tmp23ft35lz.csv\n",
      "Keyboard interruption in main thread... closing server.\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from meteostat import Point, Daily\n",
    "import geohash2\n",
    "from utils_main_holidays import extract_public_Holiday_v2\n",
    "import os\n",
    "import tempfile\n",
    "import platform\n",
    "import joblib\n",
    "\n",
    "# Load your trained model and encoder\n",
    "try:\n",
    "    # with open('best_model_XGBoost.pkl', 'rb') as f:\n",
    "    #     model = pickle.load(f)\n",
    "    \n",
    "    # with open('onehot_encoder.pkl', 'rb') as f:\n",
    "    #     encoder = pickle.load(f)\n",
    "    \n",
    "    # Load network and location options from CSV\n",
    "    network_df = pd.read_csv('network_list.csv')\n",
    "    location_df = pd.read_csv('location_list.csv')\n",
    "    otcRatio = pd.read_csv('jeki_truth_data_reference.csv')\n",
    "    holiday = pd.concat([extract_public_Holiday_v2(year, \"JP\") for year in [2024, 2025]])\n",
    "    \n",
    "    print(\"All files loaded successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading files: {e}\")\n",
    "    # Create dummy data for testing if files don't exist\n",
    "    network_df = pd.DataFrame({'NetworkId': ['Network1', 'Network2'], 'ReferenceId': ['Ref1', 'Ref2']})\n",
    "    location_df = pd.DataFrame({\n",
    "        'ReferenceId': ['Ref1', 'Ref2'], \n",
    "        'lat': [35.6762, 35.6895], \n",
    "        'lon': [139.6503, 139.6917],\n",
    "        'spotsPerHour': [4, 6],\n",
    "        'spotDuration': [15, 20],\n",
    "        'dwellTime': [30, 45],\n",
    "        'loopLength': [120, 180]\n",
    "    })\n",
    "    otcRatio = pd.DataFrame({\n",
    "        'referenceId': ['Ref1', 'Ref2'],\n",
    "        'share': [0.8, 0.9],\n",
    "        'mediaRatio': [0.7, 0.8]\n",
    "    })\n",
    "    holiday = pd.DataFrame({'date': [], 'Day_Type_2': []})\n",
    "\n",
    "# Generate geohash5 and geohash6 columns from lat/lon\n",
    "location_df['geohash5'] = location_df.apply(lambda row: geohash2.encode(row['lat'], row['lon'], precision=5), axis=1)\n",
    "location_df['geohash6'] = location_df.apply(lambda row: geohash2.encode(row['lat'], row['lon'], precision=6), axis=1)\n",
    "\n",
    "network_names = sorted(network_df['NetworkId'].unique().tolist())\n",
    "location_names = sorted(location_df['ReferenceId'].unique().tolist())\n",
    "\n",
    "# Spot calculation functions\n",
    "def check_spot(spotsHour, spotDur):\n",
    "    return spotsHour * (spotDur / (spotDur + 15))\n",
    "\n",
    "def spotPV(spotDurMult, spotGet, avgPerMin, pv):\n",
    "    return min(spotDurMult * spotGet * avgPerMin, pv)\n",
    "\n",
    "def check_dwell(dwellTime, loopLength):\n",
    "    if dwellTime < 10:\n",
    "        return 0.6\n",
    "    elif dwellTime >= 10 and dwellTime >= loopLength:\n",
    "        return dwellTime / loopLength\n",
    "    elif dwellTime >= 10 and dwellTime < loopLength:\n",
    "        return 1\n",
    "\n",
    "def spot_calc(pv, dwellTime, loopLength, spotsHour, spotDur):\n",
    "    avgPerMin = pv / 60 if dwellTime <= 60 else (pv / 60) * (dwellTime / 60)\n",
    "    spotGet = check_dwell(dwellTime, loopLength)\n",
    "    spotDurMult = check_spot(spotsHour, spotDur)\n",
    "    return spotPV(spotDurMult, spotGet, avgPerMin, pv)\n",
    "\n",
    "def custom_round(value):\n",
    "    return round(value, 2) if pd.notnull(value) else 0\n",
    "\n",
    "# Global cart to hold campaign items\n",
    "campaign_cart = []\n",
    "\n",
    "# Store the latest report data for downloads\n",
    "latest_report_data = None\n",
    "\n",
    "# Excel report generation functions (from utils_main_report.py)\n",
    "def displayName(name):\n",
    "    loc = {'JPN-JEK-D-00000-00029': 'J・ADビジョン　巣鴨駅改札外',\n",
    "           'JPN-JEK-D-00000-00030': 'J・ADビジョン　新宿駅東口',\n",
    "           'JPN-JEK-D-00000-00031': 'J・ADビジョン　新宿駅南口',\n",
    "           'JPN-JEK-D-00000-00032': 'J・ADビジョン　新宿駅甲州街道改札',\n",
    "           'JPN-JEK-D-00000-00034': 'J・ADビジョン　五反田駅',\n",
    "           'JPN-JEK-D-00000-00035': 'J・ADビジョン　品川駅中央改札内',\n",
    "           'JPN-JEK-D-00000-00039': 'J・ADビジョン　有楽町駅中央改札口',\n",
    "           'JPN-JEK-D-00000-00040': 'J・ADビジョン　東京駅丸の内地下連絡通路',\n",
    "           'JPN-JEK-D-00000-00041': 'J・ADビジョン　東京駅京葉通路',\n",
    "           'JPN-JEK-D-00000-00042': 'J・ADビジョン　秋葉原駅新電気街口',\n",
    "           'JPN-JEK-D-00000-00044': 'J・ADビジョン　吉祥寺駅南北自由通路',\n",
    "           'JPN-JEK-D-00000-00045': 'J・ADビジョン　浦和駅改札口',\n",
    "           'JPN-JEK-D-00000-00046': 'J・ADビジョン　大宮駅中央改札',\n",
    "           'JPN-JEK-D-00000-00047': 'J・ADビジョン　横浜駅中央通路',\n",
    "           'JPN-JEK-D-00000-00048': 'J・ADビジョン　JR横浜タワーアトリウム',\n",
    "           'JPN-JEK-D-00000-00049': 'J・ADビジョン　高田馬場駅スマイル・ステーションビジョン',\n",
    "           'JPN-JEK-D-00000-00050': 'J・ADビジョン　池袋駅中央改札内',\n",
    "           'JPN-JEK-D-00000-00051': 'J・ADビジョン　桜木町駅',\n",
    "           'JPN-JEK-D-00000-00052': 'J・ADビジョン　横浜駅南改札内',\n",
    "           'JPN-JEK-D-00000-00058': 'J・ADビジョン　東京駅新幹線北乗換口',\n",
    "           'JPN-JEK-D-00000-00059': 'J・ADビジョン　東京駅新幹線南乗換口',\n",
    "           'JPN-JEK-D-00000-00060': 'J・ADビジョン　恵比寿駅西口',\n",
    "           'JPN-JEK-D-00000-00061': 'J・ADビジョン　赤羽駅北改札',\n",
    "           'JPN-JEK-D-00000-00960': 'J・ADビジョン　八王子駅自由通路南',\n",
    "           'JPN-JEK-D-00000-00961': 'J・ADビジョン　上野駅公園改札内',\n",
    "           'JPN-JEK-D-00000-04333': 'J・ADビジョン 新橋駅北改札',\n",
    "           'JPN-JEK-D-00000-04334': 'J・ADビジョン 新橋駅南改札',\n",
    "           'JPN-JEK-D-00000-00036': 'J・ADビジョン　高輪ゲートウェイ駅',\n",
    "           'JPN-JEK-N-00000-00055': '[2025]J・adビジョン ステーションネットワーク'}\n",
    "    return loc.get(name, name)\n",
    "\n",
    "def networkSum_(df, name):\n",
    "    df_copy = df.copy()\n",
    "    df_copy[['gender', 'age']] = df_copy['agegender'].str.split('_', n=1, expand=True)\n",
    "    df_copy['age'] = df_copy['age'] + '_Impressions'\n",
    "    df_copy['gender_age'] = df_copy['gender'] + '_' + df_copy['age']\n",
    "    \n",
    "    # Group and sum PV\n",
    "    network_df = df_copy.groupby(['date', 'hour_group', 'gender_age'])['PV'].sum().reset_index()\n",
    "    \n",
    "    # Pivot to wide format\n",
    "    pivot_df = network_df.pivot_table(index=['date', 'hour_group'],\n",
    "                                     columns='gender_age', values='PV', fill_value=0).reset_index()\n",
    "    \n",
    "    # Fill missing columns\n",
    "    expected_cols = [f'{gender}_{age}_Impressions' for gender in ['female', 'male'] for age in ['10_19', '20_29', '30_39', '40_49', '50_59', '60_plus']]\n",
    "    for col in expected_cols:\n",
    "        if col not in pivot_df:\n",
    "            pivot_df[col] = 0\n",
    "    \n",
    "    # Reorder columns\n",
    "    location = displayName(name)\n",
    "    pivot_df['Location'] = location\n",
    "    pivot_df['Reference_Id'] = name\n",
    "    pivot_df = pivot_df[['Location', 'date', 'hour_group', 'Reference_Id'] + expected_cols]\n",
    "    \n",
    "    # Calculate Total PV\n",
    "    pivot_df['Total Impressions'] = pivot_df[expected_cols].sum(axis=1)\n",
    "    impression_cols = expected_cols + ['Total Impressions']\n",
    "    pivot_df[impression_cols] = pivot_df[impression_cols].astype(int)\n",
    "    pivot_df = pivot_df.sort_values(by=['date', 'hour_group'])\n",
    "    pivot_df['date'] = pd.to_datetime(pivot_df['date'])\n",
    "\n",
    "    # Format date nicely\n",
    "    if platform.system() == 'Windows':\n",
    "        pivot_df['date'] = pivot_df['date'].dt.strftime('%A, %#d %B, %Y')\n",
    "    else:\n",
    "        pivot_df['date'] = pivot_df['date'].dt.strftime('%A, %-d %B, %Y')\n",
    "\n",
    "    return pivot_df\n",
    "\n",
    "def ageGender_script(df):\n",
    "    # Age breakdown\n",
    "    age_order = ['10-19', '20-29', '30-39', '40-49', '50-59', '60_plus']\n",
    "    df_copy = df.copy()\n",
    "    df_copy['age'] = df_copy['agegender'].str.extract(r'(\\d+)', expand=False).astype(int)\n",
    "    df_copy['age_group'] = pd.cut(df_copy['age'], bins=[9, 19, 29, 39, 49, 59, 200], \n",
    "                                 labels=age_order, right=True)\n",
    "    \n",
    "    age_summary = df_copy.groupby('age_group')['PV'].sum().reset_index()\n",
    "    age_summary.columns = ['Age', 'Impression']\n",
    "    age_summary['Percentage'] = (age_summary['Impression'] / age_summary['Impression'].sum())\n",
    "    age_summary = age_summary[['Age', 'Percentage', 'Impression']]\n",
    "    \n",
    "    # Gender breakdown\n",
    "    df_copy['gender'] = df_copy['agegender'].str.extract(r'(female|male)')\n",
    "    gender_summary = df_copy.groupby('gender')['PV'].sum().reset_index()\n",
    "    gender_summary.columns = ['Gender', 'Impression']\n",
    "    gender_summary['Percentage'] = (gender_summary['Impression'] / gender_summary['Impression'].sum())\n",
    "    gender_summary = gender_summary[['Gender', 'Percentage', 'Impression']]\n",
    "\n",
    "    # Age-Gender breakdown\n",
    "    agegender_summary = df_copy.groupby('agegender')['PV'].sum().reset_index()\n",
    "    agegender_summary.columns = ['AgeGender', 'Impression']\n",
    "    agegender_summary['Percentage'] = agegender_summary['Impression'] / agegender_summary['Impression'].sum()\n",
    "    \n",
    "    agegender_pivot = agegender_summary.set_index('AgeGender')[['Percentage', 'Impression']].T\n",
    "    agegender_pivot.loc['Percentage'] = agegender_pivot.loc['Percentage'].astype(float).round(10)\n",
    "    agegender_pivot.loc['Impression'] = agegender_pivot.loc['Impression'].apply(lambda x: f\"{int(x):,}\")\n",
    "    \n",
    "    # Age-Gender per location\n",
    "    agegender_overall = df_copy.groupby(['Reference_Id', 'agegender'])['PV'].sum().reset_index()\n",
    "    agegender_overall.columns = ['Reference_Id', 'AgeGender', 'Impression']\n",
    "    agegender_overall['Percentage'] = agegender_overall.groupby('Reference_Id')['Impression'].transform(lambda x: x / x.sum())\n",
    "    agegender_overall = agegender_overall.pivot(index='Reference_Id', columns='AgeGender', values=['Impression', 'Percentage'])\n",
    "    \n",
    "    return age_summary, gender_summary, agegender_pivot, agegender_overall\n",
    "\n",
    "def generate_excel_report(df):\n",
    "    \"\"\"Generate Excel report using the utils_main_report.py logic\"\"\"\n",
    "    try:\n",
    "        # Prepare data\n",
    "        df_report = df.copy()\n",
    "        \n",
    "        # Map hours to hour groups\n",
    "        hour_groups_train_channel = {\n",
    "            5: '05-10', 6: '05-10', 7: '05-10', 8: '05-10', 9: '05-10', \n",
    "            10: '10-18', 11: '10-18', 12: '10-18', 13: '10-18', 14: '10-18', \n",
    "            15: '10-18', 16: '10-18', 17: '10-18', \n",
    "            18: '18-24', 19: '18-24', 20: '18-24', 21: '18-24', 22: '18-24', 23: '18-24'\n",
    "        }\n",
    "        \n",
    "        df_report[\"hour_group\"] = df_report[\"hour\"].map(hour_groups_train_channel)\n",
    "        df_report = df_report.rename(columns={\"SpotImpressions\": \"PV\"})\n",
    "        df_report['date'] = pd.to_datetime(df_report['date'])\n",
    "        \n",
    "        # Create temporary file\n",
    "        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.xlsx')\n",
    "        \n",
    "        with pd.ExcelWriter(temp_file.name, engine='openpyxl') as writer:\n",
    "            # Sheet 1: Overall Performance\n",
    "            overall_perf = df_report.groupby(\"ReferenceId\", as_index=False)[\"PV\"].sum()\n",
    "            overall_perf = overall_perf.rename(columns={\"PV\": \"Impression\"})\n",
    "            overall_perf.to_excel(writer, sheet_name=\"Overall Performance\", index=False)\n",
    "            \n",
    "            # Sheet 2: Daily Summary\n",
    "            daily = df_report.groupby([\"date\"], as_index=False)[\"PV\"].sum()\n",
    "            daily = daily.rename(columns={\"PV\": \"Impression\"})\n",
    "            daily['date'] = daily['date'].dt.strftime('%Y-%m-%d')\n",
    "            daily.to_excel(writer, sheet_name=\"Daily Summary\", index=False)\n",
    "            \n",
    "            # Sheet 3: Age Gender Analysis\n",
    "            df_report_renamed = df_report.rename(columns={\"ReferenceId\": \"Reference_Id\"})\n",
    "            age_summary, gender_summary, agegender_pivot, agegender_overall = ageGender_script(df_report_renamed)\n",
    "            age_summary.to_excel(writer, sheet_name=\"Age Gender\", startrow=0, index=False)\n",
    "            gender_summary.to_excel(writer, sheet_name=\"Age Gender\", startrow=0, startcol=4, index=False)\n",
    "            agegender_pivot.to_excel(writer, sheet_name=\"Age Gender\", startrow=10)\n",
    "            agegender_overall.to_excel(writer, sheet_name=\"Age Gender\", startrow=15)\n",
    "\n",
    "            # Sheet 4: Hourly Summary\n",
    "            hourly = df_report.groupby([\"hour\"], as_index=False)[\"PV\"].sum()\n",
    "            hourly = hourly.rename(columns={\"PV\": \"Impression\"})\n",
    "            hourly.to_excel(writer, sheet_name=\"Hourly Summary\", index=False)\n",
    "\n",
    "            # Sheet 5: Network Summary\n",
    "            overall_name = 'JPN-JEK-N-00000-00055'\n",
    "            network_summary = networkSum_(df_report_renamed, overall_name)\n",
    "            network_summary.to_excel(writer, sheet_name=\"Network Summary\", index=False)\n",
    "\n",
    "            # Individual location sheets\n",
    "            reference_ids = df_report['ReferenceId'].unique()\n",
    "            for ref_id in reference_ids:\n",
    "                tmp = df_report_renamed[df_report_renamed['Reference_Id'] == ref_id]\n",
    "                if not tmp.empty:\n",
    "                    network_summary = networkSum_(tmp, ref_id)\n",
    "                    loc_name = displayName(ref_id)\n",
    "                    # Sanitize sheet name for Excel (max 31 chars, remove invalid chars)\n",
    "                    sheet_name = loc_name[:31].replace('/', '_').replace('\\\\', '_').replace('?', '_').replace('*', '_').replace('[', '_').replace(']', '_')\n",
    "                    network_summary.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "        \n",
    "        return temp_file.name\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error generating Excel report: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_weather_label(date_str, lat, lon):\n",
    "    try:\n",
    "        date = datetime.strptime(date_str, \"%Y-%m-%d\")\n",
    "        point = Point(lat, lon)\n",
    "        daily = Daily(point, date, date)\n",
    "        weather = daily.fetch()\n",
    "        if weather.empty:\n",
    "            return \"sunny\"  # default fallback\n",
    "        w = weather.iloc[0]\n",
    "        prcp = w.get('prcp', 0) or 0\n",
    "        snow = w.get('snow', 0) or 0\n",
    "        tavg = w.get('tavg', 15) or 15\n",
    "        if snow > 0:\n",
    "            return \"snow\"\n",
    "        elif prcp > 0:\n",
    "            return \"rain\"\n",
    "        elif tavg < 5:\n",
    "            return \"cold\"\n",
    "        else:\n",
    "            return \"sunny\"\n",
    "    except Exception as e:\n",
    "        print(f\"Weather API error: {e}\")\n",
    "        return \"sunny\"  # fallback\n",
    "\n",
    "def hour_type_to_hours(hour_type):\n",
    "    mapping = {\n",
    "        'morning': list(range(5, 12)),\n",
    "        'afternoon': list(range(12, 18)),\n",
    "        'evening': list(range(18, 24)),\n",
    "        'night': list(range(0, 5)),\n",
    "        'full': list(range(5, 24))\n",
    "    }\n",
    "    return mapping.get(hour_type.lower(), [])\n",
    "\n",
    "def generate_date_range(start, end):\n",
    "    return pd.date_range(start=start, end=end)\n",
    "\n",
    "def add_to_cart(item_type, name, start_date, end_date, hour_types, spots_per_hour):\n",
    "    if not name:\n",
    "        return \"Please select a name\", get_cart_display(), update_remove_choices()\n",
    "    \n",
    "    if not start_date or not end_date:\n",
    "        return \"Please select both start and end dates\", get_cart_display(), update_remove_choices()\n",
    "    \n",
    "    if not hour_types:\n",
    "        return \"Please select at least one hour type\", get_cart_display(), update_remove_choices()\n",
    "    \n",
    "    try:\n",
    "        start_dt = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "        end_dt = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "        if start_dt > end_dt:\n",
    "            return \"End date must be after start date\", get_cart_display(), update_remove_choices()\n",
    "    except ValueError:\n",
    "        return \"Invalid date format\", get_cart_display(), update_remove_choices()\n",
    "    \n",
    "    item = {\n",
    "        'type': item_type,\n",
    "        'name': name,\n",
    "        'start_date': start_date,\n",
    "        'end_date': end_date,\n",
    "        'hour_type': hour_types if isinstance(hour_types, list) else [hour_types],\n",
    "        'spots_per_hour': int(spots_per_hour) if spots_per_hour else 1\n",
    "    }\n",
    "    \n",
    "    campaign_cart.append(item)\n",
    "    return f\"Added: {item_type} - {name}\", get_cart_display(), update_remove_choices()\n",
    "\n",
    "def get_cart_display():\n",
    "    if not campaign_cart:\n",
    "        return pd.DataFrame(columns=['Type', 'Name', 'Start Date', 'End Date', 'Hour Types', 'Spots/Hour'])\n",
    "    \n",
    "    display_data = []\n",
    "    for i, item in enumerate(campaign_cart):\n",
    "        display_data.append({\n",
    "            'Index': i,\n",
    "            'Type': item['type'],\n",
    "            'Name': item['name'],\n",
    "            'Start Date': item['start_date'],\n",
    "            'End Date': item['end_date'],\n",
    "            'Hour Types': ', '.join(item['hour_type']),\n",
    "            'Spots/Hour': item['spots_per_hour']\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(display_data)\n",
    "\n",
    "def update_remove_choices():\n",
    "    if not campaign_cart:\n",
    "        return gr.update(choices=[])\n",
    "    choices = [f\"{i}: {item['type']} - {item['name']}\" for i, item in enumerate(campaign_cart)]\n",
    "    return gr.update(choices=choices)\n",
    "\n",
    "def remove_from_cart(selected_item):\n",
    "    if not selected_item or not campaign_cart:\n",
    "        return \"No item selected or cart is empty\", get_cart_display(), update_remove_choices()\n",
    "    \n",
    "    try:\n",
    "        index = int(selected_item.split(':')[0])\n",
    "        if 0 <= index < len(campaign_cart):\n",
    "            removed_item = campaign_cart.pop(index)\n",
    "            return f\"Removed: {removed_item['type']} - {removed_item['name']}\", get_cart_display(), update_remove_choices()\n",
    "        else:\n",
    "            return \"Invalid selection\", get_cart_display(), update_remove_choices()\n",
    "    except (ValueError, IndexError):\n",
    "        return \"Invalid selection format\", get_cart_display(), update_remove_choices()\n",
    "\n",
    "def clear_cart():\n",
    "    campaign_cart.clear()\n",
    "    return \"Cart cleared successfully\", get_cart_display(), update_remove_choices()\n",
    "\n",
    "def predict(cart):\n",
    "    if not cart:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    data = []\n",
    "    agegender_keys = [\n",
    "        'female_10_19', 'female_20_29', 'female_30_39', 'female_40_49', 'female_50_59', 'female_60_plus',\n",
    "        'male_10_19', 'male_20_29', 'male_30_39', 'male_40_49', 'male_50_59', 'male_60_plus'\n",
    "    ]\n",
    "\n",
    "    for item in cart:\n",
    "        try:\n",
    "            if item['type'] == 'Location':\n",
    "                location_data = location_df[location_df['ReferenceId'] == item['name']]\n",
    "            elif item['type'] == 'Network':\n",
    "                network_ref_ids = network_df[network_df['NetworkId'] == item['name']]['ReferenceId'].tolist()\n",
    "                location_data = location_df[location_df['ReferenceId'].isin(network_ref_ids)]\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            if location_data.empty:\n",
    "                continue\n",
    "\n",
    "            for _, loc in location_data.iterrows():\n",
    "                date_range = generate_date_range(item['start_date'], item['end_date'])\n",
    "                for date in date_range:\n",
    "                    date_str = date.strftime('%Y-%m-%d')\n",
    "                    weather_label = get_weather_label(date_str, loc['lat'], loc['lon'])\n",
    "                    for hour_type in item['hour_type']:\n",
    "                        for hour in hour_type_to_hours(hour_type):\n",
    "                            for agegender in agegender_keys:\n",
    "                                row = {\n",
    "                                    'date': date_str,\n",
    "                                    'Reference_Id': loc['ReferenceId'],\n",
    "                                    'geohash5': loc['geohash5'],\n",
    "                                    'geohash6': loc['geohash6'],\n",
    "                                    'hour': hour,\n",
    "                                    'agegender': agegender,\n",
    "                                    'weather': weather_label,\n",
    "                                    'spotsPerHour': item['spots_per_hour'],\n",
    "                                    'spotDuration': loc['spotDuration'],\n",
    "                                    'dwellTime': loc['dwellTime'],\n",
    "                                    'loopLength': loc['loopLength']\n",
    "                                }\n",
    "                                data.append(row)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing item {item}: {e}\")\n",
    "            continue\n",
    "\n",
    "    if not data:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    \n",
    "    # Merge with holiday data if available\n",
    "    if not holiday.empty:\n",
    "        df = df.merge(holiday[['date', 'Day_Type_2']], on='date', how='left')\n",
    "        df.rename(columns={'Day_Type_2': 'Day_Type'}, inplace=True)\n",
    "    else:\n",
    "        df['Day_Type'] = 'regular'\n",
    "    \n",
    "    df['day_of_week'] = df['date'].dt.day_name()\n",
    "    print(df.head(10))\n",
    "    df.to_csv(\"TrainingData_Test.csv\", index=False, encoding='utf-8-sig')\n",
    "    model = joblib.load('best_model_XGBoost.pkl')\n",
    "    encoder = joblib.load('onehot_encoder.pkl')\n",
    "    \n",
    "    # Try prediction if model is available\n",
    "    try:\n",
    "        X_new = df[['geohash5', 'geohash6', 'Day_Type','day_of_week', 'weather','hour','agegender']]\n",
    "        X_new_encoded = encoder.transform(X_new)\n",
    "        # Predict\n",
    "        predictions = model.predict(X_new_encoded)\n",
    "        \n",
    "        # Store predictions\n",
    "        df[\"predicted_impressions\"] = predictions\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Prediction error: {e}\")\n",
    "        df['predicted_impressions'] = np.random.randint(100, 1000, len(df))  # dummy data for testing\n",
    "\n",
    "    # Merge with OTC ratio data\n",
    "    df = df.merge(otcRatio, left_on=\"Reference_Id\", right_on=\"referenceId\", how=\"left\")\n",
    "    df[\"NonSpotImpressions\"] = df[\"predicted_impressions\"] * (df[\"share\"] * df[\"mediaRatio\"])\n",
    "    df[\"NonSpotImpressions\"] = df[\"NonSpotImpressions\"].replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "    # Calculate spot impressions\n",
    "    est_spot_PV = []\n",
    "    for _, row1 in df.iterrows():\n",
    "        tmpSpot = custom_round(spot_calc(row1['NonSpotImpressions'], row1['dwellTime'], \n",
    "                                       row1['loopLength'], row1['spotsPerHour'], row1['spotDuration']))\n",
    "        est_spot_PV.append(tmpSpot)\n",
    "\n",
    "    df['SpotImpressions'] = est_spot_PV\n",
    "    df['predicted_impressions'] = df['predicted_impressions'].round(2)\n",
    "    df['NonSpotImpressions'] = df['NonSpotImpressions'].round(2)\n",
    "    df['SpotImpressions'] = df['SpotImpressions']\n",
    "    return df\n",
    "\n",
    "def generate_report():\n",
    "    global latest_report_data\n",
    "    \n",
    "    if not campaign_cart:\n",
    "        return pd.DataFrame(columns=['Message']).assign(Message=['No items in cart. Please add items first.'])\n",
    "    \n",
    "    try:\n",
    "        result_df = predict(campaign_cart)\n",
    "        if result_df.empty:\n",
    "            return pd.DataFrame(columns=['Message']).assign(Message=['No data generated. Please check your selections.'])\n",
    "        \n",
    "        # Store the full data for downloads\n",
    "        latest_report_data = result_df.copy()\n",
    "        \n",
    "        # Return data in the specified format\n",
    "        output_df = result_df[['Reference_Id', 'date', 'hour', 'agegender', 'predicted_impressions', 'NonSpotImpressions', 'SpotImpressions']].copy()\n",
    "        \n",
    "        # Rename columns to match the exact format requested\n",
    "        output_df = output_df.rename(columns={\n",
    "            'Reference_Id': 'ReferenceId',\n",
    "            'predicted_impressions': 'predcited_impressions'  # keeping the typo as specified\n",
    "        })\n",
    "        \n",
    "        # Sort by ReferenceId, date, hour, and agegender for better readability\n",
    "        output_df = output_df.sort_values(['ReferenceId', 'date', 'hour', 'agegender']).reset_index(drop=True)\n",
    "        \n",
    "        return output_df\n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error generating report: {str(e)}\"\n",
    "        print(error_msg)\n",
    "        return pd.DataFrame(columns=['Error']).assign(Error=[error_msg])\n",
    "\n",
    "def download_full_data():\n",
    "    \"\"\"Download full data as CSV\"\"\"\n",
    "    global latest_report_data\n",
    "\n",
    "    if latest_report_data is None or latest_report_data.empty:\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        # Prepare the data\n",
    "        df = latest_report_data[['Reference_Id', 'date', 'hour', 'agegender', 'predicted_impressions', 'NonSpotImpressions', 'SpotImpressions']].copy()\n",
    "        df = df.rename(columns={'Reference_Id': 'ReferenceId', 'predicted_impressions': 'predcited_impressions'})\n",
    "        df['predcited_impressions'] = df['predcited_impressions'].round(2)\n",
    "        df['NonSpotImpressions'] = df['NonSpotImpressions'].round(2)\n",
    "        df['SpotImpressions'] = df['SpotImpressions'].round(2)\n",
    "\n",
    "        # Create temporary file with proper extension\n",
    "        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.csv')\n",
    "        df.to_csv(temp_file.name, index=False)\n",
    "        temp_file.close()\n",
    "\n",
    "        print(f\"CSV generated: {temp_file.name}\")\n",
    "        return temp_file.name\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving CSV: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def download_excel_report():\n",
    "    \"\"\"Download the Excel report\"\"\"\n",
    "    global latest_report_data\n",
    "    \n",
    "    if latest_report_data is None or latest_report_data.empty:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Prepare data for Excel report\n",
    "        excel_df = latest_report_data.copy()\n",
    "        excel_file = generate_excel_report(excel_df)\n",
    "        \n",
    "        if excel_file:\n",
    "            print(f\"Excel generated: {excel_file}\")\n",
    "            return excel_file\n",
    "        else:\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error generating Excel: {e}\")\n",
    "        return None\n",
    "\n",
    "# Create the Gradio interface\n",
    "with gr.Blocks(title=\"Post Campaign Report Tool\") as demo:\n",
    "    gr.Markdown(\"# Post Campaign Report Data Generation Tool\")\n",
    "    \n",
    "    with gr.Tab(\"Add Network Campaign\"):\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                name_n = gr.Dropdown(choices=network_names, label=\"Select Network Name\", value=None)\n",
    "                start_date_n = gr.Textbox(label=\"Start Date (YYYY-MM-DD)\", placeholder=\"2024-01-01\")\n",
    "                end_date_n = gr.Textbox(label=\"End Date (YYYY-MM-DD)\", placeholder=\"2024-01-31\")\n",
    "            with gr.Column():\n",
    "                hour_type_n = gr.CheckboxGroup(\n",
    "                    choices=['morning', 'afternoon', 'evening', 'night', 'full'], \n",
    "                    label=\"Hour Types\",\n",
    "                    value=[]\n",
    "                )\n",
    "                spots_n = gr.Number(label=\"Spots per Hour\", value=1, minimum=1)\n",
    "                btn_n = gr.Button(\"Add Network to Cart\", variant=\"primary\")\n",
    "        \n",
    "        out_n = gr.Textbox(label=\"Status Message\")\n",
    "    \n",
    "    with gr.Tab(\"Add Location Campaign\"):\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                name_l = gr.Dropdown(choices=location_names, label=\"Select Location Name\", value=None)\n",
    "                start_date_l = gr.Textbox(label=\"Start Date (YYYY-MM-DD)\", placeholder=\"2024-01-01\")\n",
    "                end_date_l = gr.Textbox(label=\"End Date (YYYY-MM-DD)\", placeholder=\"2024-01-31\")\n",
    "            with gr.Column():\n",
    "                hour_type_l = gr.CheckboxGroup(\n",
    "                    choices=['morning', 'afternoon', 'evening', 'night', 'full'], \n",
    "                    label=\"Hour Types\",\n",
    "                    value=[]\n",
    "                )\n",
    "                spots_l = gr.Number(label=\"Spots per Hour\", value=1, minimum=1)\n",
    "                btn_l = gr.Button(\"Add Location to Cart\", variant=\"primary\")\n",
    "        \n",
    "        out_l = gr.Textbox(label=\"Status Message\")\n",
    "    \n",
    "    with gr.Tab(\"Cart Management\"):\n",
    "        gr.Markdown(\"## Current Cart Items\")\n",
    "        cart_display = gr.Dataframe(label=\"Cart Contents\", interactive=False)\n",
    "        \n",
    "        with gr.Row():\n",
    "            with gr.Column(scale=3):\n",
    "                remove_dropdown = gr.Dropdown(label=\"Select Item to Remove\", choices=[], interactive=True)\n",
    "            with gr.Column(scale=1):\n",
    "                remove_btn = gr.Button(\"Remove Selected\", variant=\"secondary\")\n",
    "            with gr.Column(scale=1):\n",
    "                clear_btn = gr.Button(\"Clear All\", variant=\"stop\")\n",
    "        \n",
    "        cart_message = gr.Textbox(label=\"Cart Status\", interactive=False)\n",
    "    \n",
    "    with gr.Tab(\"Generate Report\"):\n",
    "        gr.Markdown(\"## Generate Impression Report\")\n",
    "        gr.Markdown(\"Click the button below to generate a report based on all items in your cart.\")\n",
    "        \n",
    "        with gr.Row():\n",
    "            report_btn = gr.Button(\"Generate Report\", variant=\"primary\", size=\"lg\")\n",
    "        \n",
    "        report_output = gr.Dataframe(label=\"Campaign Report\", interactive=False)\n",
    "        \n",
    "        gr.Markdown(\"## Download Options\")\n",
    "        gr.Markdown(\"After generating a report, you can download the data in different formats:\")\n",
    "        \n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                gr.Markdown(\"### Full Data CSV\")\n",
    "                gr.Markdown(\"Download the complete dataset with all columns\")\n",
    "                download_csv_btn = gr.Button(\"Download Full Data (CSV)\", variant=\"secondary\")\n",
    "                csv_download = gr.File(label=\"CSV Download\", visible=False)\n",
    "            \n",
    "            with gr.Column():\n",
    "                gr.Markdown(\"### Excel Report\")\n",
    "                gr.Markdown(\"Download comprehensive Excel report with multiple sheets and analysis\")\n",
    "                download_excel_btn = gr.Button(\"Download Excel Report\", variant=\"secondary\")\n",
    "                excel_download = gr.File(label=\"Excel Download\", visible=False)\n",
    "    \n",
    "    # Event handlers\n",
    "    btn_n.click(\n",
    "        fn=add_to_cart,\n",
    "        inputs=[gr.Textbox(value=\"Network\", visible=False), name_n, start_date_n, end_date_n, hour_type_n, spots_n],\n",
    "        outputs=[out_n, cart_display, remove_dropdown]\n",
    "    )\n",
    "    \n",
    "    btn_l.click(\n",
    "        fn=add_to_cart,\n",
    "        inputs=[gr.Textbox(value=\"Location\", visible=False), name_l, start_date_l, end_date_l, hour_type_l, spots_l],\n",
    "        outputs=[out_l, cart_display, remove_dropdown]\n",
    "    )\n",
    "    \n",
    "    remove_btn.click(\n",
    "        fn=remove_from_cart,\n",
    "        inputs=[remove_dropdown],\n",
    "        outputs=[cart_message, cart_display, remove_dropdown]\n",
    "    )\n",
    "    \n",
    "    clear_btn.click(\n",
    "        fn=clear_cart,\n",
    "        outputs=[cart_message, cart_display, remove_dropdown]\n",
    "    )\n",
    "    \n",
    "    # Updated event handlers - replace the existing download event handlers\n",
    "    report_btn.click(\n",
    "        fn=generate_report,\n",
    "        outputs=[report_output]\n",
    "    )\n",
    "    \n",
    "    # CSV Download\n",
    "    download_csv_btn.click(\n",
    "        fn=download_full_data,\n",
    "        outputs=[csv_download]\n",
    "    ).then(\n",
    "        fn=lambda x: gr.update(visible=True) if x else gr.update(visible=False),\n",
    "        inputs=[csv_download],\n",
    "        outputs=[csv_download]\n",
    "    )\n",
    "    \n",
    "    # Excel Download  \n",
    "    download_excel_btn.click(\n",
    "        fn=download_excel_report,\n",
    "        outputs=[excel_download]\n",
    "    ).then(\n",
    "        fn=lambda x: gr.update(visible=True) if x else gr.update(visible=False),\n",
    "        inputs=[excel_download],\n",
    "        outputs=[excel_download]\n",
    "    )\n",
    "    \n",
    "    # Load initial cart display\n",
    "    demo.load(\n",
    "        fn=lambda: (get_cart_display(), update_remove_choices()),\n",
    "        outputs=[cart_display, remove_dropdown]\n",
    "    )\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    demo.launch(debug=True, share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8ddd33ac-643f-41ed-a8e4-e03d7e9b3247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(encoder))  # Should be <class 'sklearn.preprocessing._encoders.OneHotEncoder'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af05cf7f-7b5b-492f-8816-f3ae7d8402cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2514dcac-ebd0-45b2-8978-53fed99f3228",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ReferenceId</th>\n",
       "      <th>spotsPerHour</th>\n",
       "      <th>dwellTime</th>\n",
       "      <th>loopLength</th>\n",
       "      <th>spotDuration</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>geohash5</th>\n",
       "      <th>geohash6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JPN-JEK-D-00000-00029</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>360</td>\n",
       "      <td>15</td>\n",
       "      <td>35.733539</td>\n",
       "      <td>139.739261</td>\n",
       "      <td>xn777</td>\n",
       "      <td>xn777c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JPN-JEK-D-00000-00030</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>360</td>\n",
       "      <td>15</td>\n",
       "      <td>35.691599</td>\n",
       "      <td>139.701027</td>\n",
       "      <td>xn774</td>\n",
       "      <td>xn774c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JPN-JEK-D-00000-00031</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>360</td>\n",
       "      <td>15</td>\n",
       "      <td>35.689607</td>\n",
       "      <td>139.700571</td>\n",
       "      <td>xn774</td>\n",
       "      <td>xn774c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JPN-JEK-D-00000-00032</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>360</td>\n",
       "      <td>15</td>\n",
       "      <td>35.688715</td>\n",
       "      <td>139.700862</td>\n",
       "      <td>xn774</td>\n",
       "      <td>xn774b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JPN-JEK-D-00000-00034</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>360</td>\n",
       "      <td>15</td>\n",
       "      <td>35.626069</td>\n",
       "      <td>139.723606</td>\n",
       "      <td>xn76e</td>\n",
       "      <td>xn76em</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>JPN-JEK-D-00000-00035</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>360</td>\n",
       "      <td>15</td>\n",
       "      <td>35.628471</td>\n",
       "      <td>139.738760</td>\n",
       "      <td>xn76e</td>\n",
       "      <td>xn76ev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>JPN-JEK-D-00000-00039</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>360</td>\n",
       "      <td>15</td>\n",
       "      <td>35.674765</td>\n",
       "      <td>139.763051</td>\n",
       "      <td>xn76u</td>\n",
       "      <td>xn76uq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>JPN-JEK-D-00000-00040</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>360</td>\n",
       "      <td>15</td>\n",
       "      <td>35.681846</td>\n",
       "      <td>139.765255</td>\n",
       "      <td>xn76u</td>\n",
       "      <td>xn76ur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>JPN-JEK-D-00000-00041</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>360</td>\n",
       "      <td>15</td>\n",
       "      <td>35.679865</td>\n",
       "      <td>139.767138</td>\n",
       "      <td>xn76u</td>\n",
       "      <td>xn76ur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>JPN-JEK-D-00000-00042</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>360</td>\n",
       "      <td>15</td>\n",
       "      <td>35.698444</td>\n",
       "      <td>139.772554</td>\n",
       "      <td>xn77h</td>\n",
       "      <td>xn77hd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>JPN-JEK-D-00000-00044</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>360</td>\n",
       "      <td>15</td>\n",
       "      <td>35.703130</td>\n",
       "      <td>139.579715</td>\n",
       "      <td>xn770</td>\n",
       "      <td>xn7705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>JPN-JEK-D-00000-00045</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>360</td>\n",
       "      <td>15</td>\n",
       "      <td>35.858742</td>\n",
       "      <td>139.657363</td>\n",
       "      <td>xn77c</td>\n",
       "      <td>xn77cz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>JPN-JEK-D-00000-00046</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>360</td>\n",
       "      <td>15</td>\n",
       "      <td>35.906310</td>\n",
       "      <td>139.624388</td>\n",
       "      <td>xn7k3</td>\n",
       "      <td>xn7k30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>JPN-JEK-D-00000-00047</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>360</td>\n",
       "      <td>15</td>\n",
       "      <td>35.465922</td>\n",
       "      <td>139.622387</td>\n",
       "      <td>xn73c</td>\n",
       "      <td>xn73c0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>JPN-JEK-D-00000-00048</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>360</td>\n",
       "      <td>15</td>\n",
       "      <td>35.466113</td>\n",
       "      <td>139.621917</td>\n",
       "      <td>xn73c</td>\n",
       "      <td>xn73c0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>JPN-JEK-D-00000-00049</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>360</td>\n",
       "      <td>15</td>\n",
       "      <td>35.713467</td>\n",
       "      <td>139.704479</td>\n",
       "      <td>xn775</td>\n",
       "      <td>xn775j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>JPN-JEK-D-00000-00050</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>360</td>\n",
       "      <td>15</td>\n",
       "      <td>35.730165</td>\n",
       "      <td>139.711038</td>\n",
       "      <td>xn777</td>\n",
       "      <td>xn7770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>JPN-JEK-D-00000-00051</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>360</td>\n",
       "      <td>15</td>\n",
       "      <td>35.450761</td>\n",
       "      <td>139.631186</td>\n",
       "      <td>xn739</td>\n",
       "      <td>xn739m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>JPN-JEK-D-00000-00052</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>360</td>\n",
       "      <td>15</td>\n",
       "      <td>35.465378</td>\n",
       "      <td>139.622424</td>\n",
       "      <td>xn73c</td>\n",
       "      <td>xn73c0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>JPN-JEK-D-00000-00058</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>360</td>\n",
       "      <td>15</td>\n",
       "      <td>35.680891</td>\n",
       "      <td>139.766823</td>\n",
       "      <td>xn76u</td>\n",
       "      <td>xn76ur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>JPN-JEK-D-00000-00059</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>360</td>\n",
       "      <td>15</td>\n",
       "      <td>35.681784</td>\n",
       "      <td>139.767173</td>\n",
       "      <td>xn76u</td>\n",
       "      <td>xn76ur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>JPN-JEK-D-00000-00060</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>360</td>\n",
       "      <td>15</td>\n",
       "      <td>35.647169</td>\n",
       "      <td>139.709802</td>\n",
       "      <td>xn76g</td>\n",
       "      <td>xn76g1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>JPN-JEK-D-00000-00061</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>360</td>\n",
       "      <td>15</td>\n",
       "      <td>35.777961</td>\n",
       "      <td>139.720772</td>\n",
       "      <td>xn77e</td>\n",
       "      <td>xn77e3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>JPN-JEK-D-00000-00960</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>360</td>\n",
       "      <td>15</td>\n",
       "      <td>35.655697</td>\n",
       "      <td>139.338959</td>\n",
       "      <td>xn74f</td>\n",
       "      <td>xn74fd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>JPN-JEK-D-00000-00961</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>360</td>\n",
       "      <td>15</td>\n",
       "      <td>35.714100</td>\n",
       "      <td>139.777409</td>\n",
       "      <td>xn77h</td>\n",
       "      <td>xn77ht</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>JPN-JEK-D-00000-04333</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>360</td>\n",
       "      <td>15</td>\n",
       "      <td>35.666378</td>\n",
       "      <td>139.758340</td>\n",
       "      <td>xn76u</td>\n",
       "      <td>xn76uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>JPN-JEK-D-00000-04334</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>360</td>\n",
       "      <td>15</td>\n",
       "      <td>35.666378</td>\n",
       "      <td>139.758340</td>\n",
       "      <td>xn76u</td>\n",
       "      <td>xn76uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>JPN-JEK-D-00000-00036</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>360</td>\n",
       "      <td>15</td>\n",
       "      <td>35.635891</td>\n",
       "      <td>139.740946</td>\n",
       "      <td>xn76e</td>\n",
       "      <td>xn76ez</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ReferenceId  spotsPerHour  dwellTime  loopLength  spotDuration  \\\n",
       "0   JPN-JEK-D-00000-00029            10         10         360            15   \n",
       "1   JPN-JEK-D-00000-00030            10         10         360            15   \n",
       "2   JPN-JEK-D-00000-00031            10         10         360            15   \n",
       "3   JPN-JEK-D-00000-00032            10         10         360            15   \n",
       "4   JPN-JEK-D-00000-00034            10         10         360            15   \n",
       "5   JPN-JEK-D-00000-00035            10         10         360            15   \n",
       "6   JPN-JEK-D-00000-00039            10         10         360            15   \n",
       "7   JPN-JEK-D-00000-00040            10         10         360            15   \n",
       "8   JPN-JEK-D-00000-00041            10         10         360            15   \n",
       "9   JPN-JEK-D-00000-00042            10         10         360            15   \n",
       "10  JPN-JEK-D-00000-00044            10         10         360            15   \n",
       "11  JPN-JEK-D-00000-00045            10         10         360            15   \n",
       "12  JPN-JEK-D-00000-00046            10         10         360            15   \n",
       "13  JPN-JEK-D-00000-00047            10         10         360            15   \n",
       "14  JPN-JEK-D-00000-00048            10         10         360            15   \n",
       "15  JPN-JEK-D-00000-00049            10         10         360            15   \n",
       "16  JPN-JEK-D-00000-00050            10         10         360            15   \n",
       "17  JPN-JEK-D-00000-00051            10         10         360            15   \n",
       "18  JPN-JEK-D-00000-00052            10         10         360            15   \n",
       "19  JPN-JEK-D-00000-00058            10         10         360            15   \n",
       "20  JPN-JEK-D-00000-00059            10         10         360            15   \n",
       "21  JPN-JEK-D-00000-00060            10         10         360            15   \n",
       "22  JPN-JEK-D-00000-00061            10         10         360            15   \n",
       "23  JPN-JEK-D-00000-00960            10         10         360            15   \n",
       "24  JPN-JEK-D-00000-00961            10         10         360            15   \n",
       "25  JPN-JEK-D-00000-04333            10         10         360            15   \n",
       "26  JPN-JEK-D-00000-04334            10         10         360            15   \n",
       "27  JPN-JEK-D-00000-00036            10         10         360            15   \n",
       "\n",
       "          lat         lon geohash5 geohash6  \n",
       "0   35.733539  139.739261    xn777   xn777c  \n",
       "1   35.691599  139.701027    xn774   xn774c  \n",
       "2   35.689607  139.700571    xn774   xn774c  \n",
       "3   35.688715  139.700862    xn774   xn774b  \n",
       "4   35.626069  139.723606    xn76e   xn76em  \n",
       "5   35.628471  139.738760    xn76e   xn76ev  \n",
       "6   35.674765  139.763051    xn76u   xn76uq  \n",
       "7   35.681846  139.765255    xn76u   xn76ur  \n",
       "8   35.679865  139.767138    xn76u   xn76ur  \n",
       "9   35.698444  139.772554    xn77h   xn77hd  \n",
       "10  35.703130  139.579715    xn770   xn7705  \n",
       "11  35.858742  139.657363    xn77c   xn77cz  \n",
       "12  35.906310  139.624388    xn7k3   xn7k30  \n",
       "13  35.465922  139.622387    xn73c   xn73c0  \n",
       "14  35.466113  139.621917    xn73c   xn73c0  \n",
       "15  35.713467  139.704479    xn775   xn775j  \n",
       "16  35.730165  139.711038    xn777   xn7770  \n",
       "17  35.450761  139.631186    xn739   xn739m  \n",
       "18  35.465378  139.622424    xn73c   xn73c0  \n",
       "19  35.680891  139.766823    xn76u   xn76ur  \n",
       "20  35.681784  139.767173    xn76u   xn76ur  \n",
       "21  35.647169  139.709802    xn76g   xn76g1  \n",
       "22  35.777961  139.720772    xn77e   xn77e3  \n",
       "23  35.655697  139.338959    xn74f   xn74fd  \n",
       "24  35.714100  139.777409    xn77h   xn77ht  \n",
       "25  35.666378  139.758340    xn76u   xn76uk  \n",
       "26  35.666378  139.758340    xn76u   xn76uk  \n",
       "27  35.635891  139.740946    xn76e   xn76ez  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c5e9292f-53db-4e77-af57-d155c26e9fa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sunny'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_weather_label('2025-05-01', 35.655697,139.338959)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
